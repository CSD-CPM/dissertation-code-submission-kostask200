{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af1e4744",
   "metadata": {},
   "source": [
    "# Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a8cad7af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library\n",
    "import os\n",
    "\n",
    "# Third-party libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import shap\n",
    "import lime\n",
    "import lime.lime_tabular\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d44d373",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "55012514",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the input path\n",
    "input_dir = \"../data/final/\"\n",
    "\n",
    "# Load the datasets\n",
    "X_train = pd.read_csv(os.path.join(input_dir, \"training_set.csv\"))\n",
    "X_test = pd.read_csv(os.path.join(input_dir, \"testing_set.csv\"))\n",
    "\n",
    "# Prepare features and target\n",
    "X = X_train.drop(columns=['YIELD'])\n",
    "y = X_train['YIELD']\n",
    "X_test_features = X_test.drop(columns=['YIELD'])\n",
    "y_test = X_test['YIELD']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "24bc6110",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping Dictionary\n",
    "indicator_labels = {\n",
    "    \"WB_CCKP_CDD\": \"Consecutive Dry Days\",\n",
    "    \"WB_CCKP_CDD65\": \"Cooling Degree Days 65°F\",\n",
    "    \"WB_CCKP_CSDI\": \"Cold Spell Duration Index\",\n",
    "    \"WB_CCKP_CWD\": \"Consecutive Wet Days\",\n",
    "    \"WB_CCKP_FD\": \"Frost Days\",\n",
    "    \"WB_CCKP_HD30\": \"Hot Days >30°C\",\n",
    "    \"WB_CCKP_HD35\": \"Hot Days >35°C\",\n",
    "    \"WB_CCKP_HD40\": \"Hot Days >40°C\",\n",
    "    \"WB_CCKP_HD42\": \"Hot Days >42°C\",\n",
    "    \"WB_CCKP_HD45\": \"Hot Days >45°C\",\n",
    "    \"WB_CCKP_HD50\": \"Hot Days >50°C\",\n",
    "    \"WB_CCKP_HDD65\": \"Heating Degree Days 65°F\",\n",
    "    \"WB_CCKP_HI35\": \"Heat Index >35°C\",\n",
    "    \"WB_CCKP_HI37\": \"Heat Index >37°C\",\n",
    "    \"WB_CCKP_HI39\": \"Heat Index >39°C\",\n",
    "    \"WB_CCKP_HI41\": \"Heat Index >41°C\",\n",
    "    \"WB_CCKP_HURS\": \"Relative Humidity\",\n",
    "    \"WB_CCKP_ID\": \"Ice Days\",\n",
    "    \"WB_CCKP_PR\": \"Precipitation\",\n",
    "    \"WB_CCKP_R20MM\": \"Heavy Rain Days (≥20mm)\",\n",
    "    \"WB_CCKP_R50MM\": \"Very Heavy Rain Days (≥50mm)\",\n",
    "    \"WB_CCKP_R95PTOT\": \"Extreme Rain (95th percentile)\",\n",
    "    \"WB_CCKP_RX1DAY\": \"Max 1-Day Precipitation\",\n",
    "    \"WB_CCKP_RX5DAY\": \"Max 5-Day Precipitation\",\n",
    "    \"WB_CCKP_SD\": \"Snow Days\",\n",
    "    \"WB_CCKP_TAS\": \"Mean Temperature\",\n",
    "    \"WB_CCKP_TASMAX\": \"Max Temperature\",\n",
    "    \"WB_CCKP_TASMIN\": \"Min Temperature\",\n",
    "    \"WB_CCKP_TNN\": \"Min of Daily Min Temperatures\",\n",
    "    \"WB_CCKP_TR\": \"Tropical Nights\",\n",
    "    \"WB_CCKP_TR23\": \"Tropical Nights >23°C\",\n",
    "    \"WB_CCKP_TR26\": \"Tropical Nights >26°C\",\n",
    "    \"WB_CCKP_TR29\": \"Tropical Nights >29°C\",\n",
    "    \"WB_CCKP_TR32\": \"Tropical Nights >32°C\",\n",
    "    \"WB_CCKP_TX84RR\": \"Max Temp on Rainy Days (84th %)\",\n",
    "    \"WB_CCKP_TXX\": \"Max of Daily Max Temperatures\",\n",
    "    \"WB_CCKP_WSDI\": \"Warm Spell Duration Index\",\n",
    "    \"ITEM_Maize\": \"Maize\",\n",
    "    \"ITEM_Wheat\": \"Wheat\",\n",
    "    \"ITEM_Barley\": \"Barley\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f0577358",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "model = joblib.load(\"../models/xgboost.joblib\")\n",
    "\n",
    "# Feature names\n",
    "feat_names = list(getattr(model, \"feature_names_in_\", X.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c19d68a",
   "metadata": {},
   "source": [
    "# Classic Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f655af79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved feature importance results in: ../results/xai\n"
     ]
    }
   ],
   "source": [
    "# Importance values\n",
    "imp = model.feature_importances_\n",
    "fi = pd.DataFrame({\"feature\": feat_names, \"importance\": imp})\n",
    "fi = fi.sort_values(\"importance\", ascending=False, ignore_index=True)\n",
    "\n",
    "# Map to readable labels\n",
    "fi[\"feature_label\"] = fi[\"feature\"].map(indicator_labels).fillna(fi[\"feature\"])\n",
    "\n",
    "# Save CSV\n",
    "outdir = \"../results/xai\"\n",
    "os.makedirs(outdir, exist_ok=True)\n",
    "fi.to_csv(os.path.join(outdir, \"feature_importance.csv\"), index=False)\n",
    "\n",
    "# Plot top 20\n",
    "fi_top = fi.head(20).iloc[::-1]\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.barh(fi_top[\"feature_label\"], fi_top[\"importance\"])\n",
    "plt.xlabel(\"Importance\")\n",
    "plt.title(\"XGBoost Feature Importance\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(outdir, \"feature_importance.png\"), dpi=200)\n",
    "plt.close()\n",
    "\n",
    "print(\"Saved feature importance results in:\", outdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cad2886",
   "metadata": {},
   "source": [
    "# SHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "887d1cfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|===================| 2435/2436 [00:39<00:00]        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved SHAP bar and beeswarm plots in: ../results/xai\n"
     ]
    }
   ],
   "source": [
    "outdir = \"../results/xai\"\n",
    "os.makedirs(outdir, exist_ok=True)\n",
    "\n",
    "# Apply mapping to get readable labels\n",
    "feat_names = list(getattr(model, \"feature_names_in_\", X.columns))\n",
    "feat_labels = [indicator_labels.get(f, f) for f in feat_names]\n",
    "\n",
    "# Make sure columns are aligned with model\n",
    "X_aligned = X[feat_names]\n",
    "X_np = X_aligned.to_numpy(dtype=np.float64, copy=True)\n",
    "\n",
    "# Explainer\n",
    "explainer = shap.TreeExplainer(model, X_np, feature_perturbation=\"interventional\")\n",
    "shap_values = explainer.shap_values(X_np)\n",
    "\n",
    "# --- Bar plot (global importance) ---\n",
    "plt.figure()\n",
    "shap.summary_plot(shap_values, X_aligned, feature_names=feat_labels, plot_type=\"bar\", show=False)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(outdir, \"shap_bar.png\"), dpi=200)\n",
    "plt.close()\n",
    "\n",
    "# --- Beeswarm plot (distribution of impacts) ---\n",
    "plt.figure()\n",
    "shap.summary_plot(shap_values, X_aligned, feature_names=feat_labels, show=False)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(outdir, \"shap_beeswarm.png\"), dpi=200)\n",
    "plt.close()\n",
    "\n",
    "print(\"Saved SHAP bar and beeswarm plots in:\", outdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d9e6b0e",
   "metadata": {},
   "source": [
    "# LIME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c76fab75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ITEM_Barley: sample 4, predicted=3637.58, actual=3033.20\n",
      "ITEM_Wheat: sample 1, predicted=4026.45, actual=4500.10\n",
      "ITEM_Maize: sample 0, predicted=9058.32, actual=10169.50\n"
     ]
    }
   ],
   "source": [
    "outdir = \"../results/xai\"\n",
    "os.makedirs(outdir, exist_ok=True)\n",
    "\n",
    "# Feature names + mapped labels\n",
    "feat_names = list(getattr(model, \"feature_names_in_\", X.columns))\n",
    "feat_labels = [indicator_labels.get(f, f) for f in feat_names]\n",
    "\n",
    "# Initialize LIME explainer\n",
    "explainer = lime.lime_tabular.LimeTabularExplainer(\n",
    "    training_data=X[feat_names].to_numpy(dtype=np.float64),\n",
    "    feature_names=feat_labels,\n",
    "    mode=\"regression\",\n",
    "    verbose=False,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Crop indicators (adjust if your one-hot names differ)\n",
    "crop_features = [\"ITEM_Barley\", \"ITEM_Wheat\", \"ITEM_Maize\"]\n",
    "\n",
    "examples = {}\n",
    "for crop in crop_features:\n",
    "    # pick the first sample in test set belonging to this crop\n",
    "    idx = X_test_features.index[X_test_features[crop] == 1][0]\n",
    "    row = X_test_features.loc[idx, feat_names].to_numpy()\n",
    "    \n",
    "    exp = explainer.explain_instance(\n",
    "        row,\n",
    "        model.predict,\n",
    "        num_features=10\n",
    "    )\n",
    "    \n",
    "    pred = exp.predicted_value\n",
    "    actual = y_test.loc[idx]\n",
    "    \n",
    "    # Save plot\n",
    "    fig = exp.as_pyplot_figure()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(outdir, f\"lime_{crop}.png\"), dpi=200)\n",
    "    plt.close(fig)\n",
    "    \n",
    "    examples[crop] = {\n",
    "        \"index\": idx,\n",
    "        \"predicted\": pred,\n",
    "        \"actual\": actual\n",
    "    }\n",
    "\n",
    "# Print summary\n",
    "for crop, info in examples.items():\n",
    "    print(f\"{crop}: sample {info['index']}, predicted={info['predicted']:.2f}, actual={info['actual']:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c8e37753",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ITEM_Barley: sample 4, predicted=3637.58, actual=3033.20\n",
      "ITEM_Wheat: sample 1, predicted=4026.45, actual=4500.10\n",
      "ITEM_Maize: sample 0, predicted=9058.32, actual=10169.50\n"
     ]
    }
   ],
   "source": [
    "outdir = \"../results/xai\"\n",
    "os.makedirs(outdir, exist_ok=True)\n",
    "\n",
    "# Feature names + mapped labels\n",
    "feat_names = list(getattr(model, \"feature_names_in_\", X.columns))\n",
    "feat_labels = [indicator_labels.get(f, f) for f in feat_names]\n",
    "\n",
    "# LIME explainer (regression)\n",
    "explainer = lime.lime_tabular.LimeTabularExplainer(\n",
    "    training_data=X[feat_names].to_numpy(dtype=np.float64),\n",
    "    feature_names=feat_labels,\n",
    "    mode=\"regression\",\n",
    "    verbose=False,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "crop_features = [\"ITEM_Barley\", \"ITEM_Wheat\", \"ITEM_Maize\"]\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6), constrained_layout=True)\n",
    "examples = {}\n",
    "\n",
    "for ax, crop in zip(axes, crop_features):\n",
    "    idx = X_test_features.index[X_test_features[crop] == 1][0]\n",
    "    row = X_test_features.loc[idx, feat_names].to_numpy()\n",
    "\n",
    "    exp = explainer.explain_instance(row, model.predict, num_features=10)\n",
    "    pred = float(exp.predicted_value)\n",
    "    actual = float(y_test.loc[idx])\n",
    "\n",
    "    # Regression: get list directly ([(name, weight), ...])\n",
    "    pairs = exp.as_list()\n",
    "    names = [p[0] for p in pairs]\n",
    "    weights = np.array([p[1] for p in pairs], dtype=float)\n",
    "\n",
    "    order = np.argsort(np.abs(weights))  # small→large; flip for top at top\n",
    "    names = [names[i] for i in order][::-1]\n",
    "    weights = weights[order][::-1]\n",
    "\n",
    "    y = np.arange(len(weights))[::-1]\n",
    "    ax.barh(y, weights)\n",
    "    ax.set_yticks(y)\n",
    "    ax.set_yticklabels(names, fontsize=8)\n",
    "    ax.axvline(0, linewidth=1)\n",
    "    ax.set_title(f\"{crop}\\nPred={pred:.2f}, Actual={actual:.2f}\")\n",
    "    ax.set_xlabel(\"Local contribution\")\n",
    "\n",
    "    examples[crop] = {\"index\": idx, \"predicted\": pred, \"actual\": actual}\n",
    "\n",
    "plt.savefig(os.path.join(outdir, \"lime_all_crops.png\"), dpi=200)\n",
    "plt.close(fig)\n",
    "\n",
    "for crop, info in examples.items():\n",
    "    print(f\"{crop}: sample {info['index']}, predicted={info['predicted']:.2f}, actual={info['actual']:.2f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dissertation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
